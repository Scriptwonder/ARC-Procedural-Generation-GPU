#pragma kernel ScanInBucketInclusive
#pragma kernel ScanInBucketExclusive
#pragma kernel ScanBucketResult
#pragma kernel ScanAddBucketResult

#define THREADS_PER_GROUP 512// Ensure that this equals the 'threadsPerGroup' const in the host script.

StructuredBuffer<uint> _Input;
RWStructuredBuffer<uint> _Result;

groupshared uint2 bucket[THREADS_PER_GROUP];

void CSScan(uint3 DTid, uint GI, uint x)
{
    // since CS40 can only support one shared memory for one shader, we use .xy and .zw as ping-ponging buffers
    // if scan a single element type like int, search and replace all .xy to .x and .zw to .y below
    /*bucket[GI] = x;

    [unroll]
    for (uint t = 1; t < THREADS_PER_GROUP; t <<= 1) {
        GroupMemoryBarrierWithGroupSync();
        uint temp = bucket[GI];
        if (GI >= t) temp += bucket[GI - t];
        GroupMemoryBarrierWithGroupSync();
        bucket[GI] = temp;
    }

    _Result[DTid.x] = bucket[GI];*/



    bucket[GI].x = x;
    bucket[GI].y = 0;

    //// Up sweep  
    [unroll]
    for (uint stride = 2; stride <= THREADS_PER_GROUP; stride <<= 1)
    {
        GroupMemoryBarrierWithGroupSync();
        if ((GI & (stride - 1)) == (stride - 1)) bucket[GI].x += bucket[GI - stride / 2].x;
    }

    if (GI == (THREADS_PER_GROUP - 1)) bucket[GI].x = 0;

    // Down sweep
    bool n = true;
    [unroll]
    for (stride = THREADS_PER_GROUP / 2; stride >= 1; stride >>= 1)
    {
        GroupMemoryBarrierWithGroupSync();

        uint a = stride - 1;
        uint b = stride | a;

        if (n)        // ping-pong between passes
        {
            if ((GI & b) == b)
            {
                bucket[GI].y = bucket[GI - stride].x + bucket[GI].x;
            }
            else
                if ((GI & a) == a)
                {
                    bucket[GI].y = bucket[GI + stride].x;
                }
                else
                {
                    bucket[GI].y = bucket[GI].x;
                }
        }
        else {
            if ((GI & b) == b)
            {
                bucket[GI].x = bucket[GI - stride].y + bucket[GI].y;
            }
            else
                if ((GI & a) == a)
                {
                    bucket[GI].x = bucket[GI + stride].y;
                }
                else
                {
                    bucket[GI].x = bucket[GI].y;
                }
        }

        n = !n;
    }

    _Result[DTid.x] = bucket[GI].y + x;
}


// Scan in each bucket.
[numthreads(THREADS_PER_GROUP, 1, 1)]
void ScanInBucketInclusive(uint DTid : SV_DispatchThreadID, uint GI : SV_GroupIndex) // CSScanInBucket
{
    uint x = _Input[DTid];
    CSScan(DTid, GI, x);
}

// Scan in each bucket.
[numthreads(THREADS_PER_GROUP, 1, 1)]
void ScanInBucketExclusive(uint DTid : SV_DispatchThreadID, uint GI : SV_GroupIndex) // CSScanInBucket
{
    uint x = DTid == 0 ? 0 : _Input[DTid - 1];
    CSScan(DTid, GI, x);
}


// Record and scan the sum of each bucket.
[numthreads(THREADS_PER_GROUP, 1, 1)]
void ScanBucketResult(uint DTid : SV_DispatchThreadID, uint GI : SV_GroupIndex)
{
    uint x = (DTid == 0) ? 0 : _Input[DTid * THREADS_PER_GROUP - 1];
    CSScan(DTid, GI, x);
}


// Add the bucket scanned result to each bucket to get the final result.
[numthreads(THREADS_PER_GROUP, 1, 1)]
void ScanAddBucketResult(uint Gid : SV_GroupID, uint3 DTid : SV_DispatchThreadID)
{
    _Result[DTid.x] = _Result[DTid.x] + _Input[Gid];
}